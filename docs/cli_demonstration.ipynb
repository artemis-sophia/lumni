{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88391b1",
   "metadata": {},
   "source": [
    "# Anna's Gift CLI - Complete Demonstration\n",
    "\n",
    "This notebook demonstrates all features and use cases of the Anna's Gift Management CLI.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Anna's Gift CLI provides comprehensive management tools for:\n",
    "- **Usage Monitoring**: Track API usage, costs, and statistics\n",
    "- **Rate Limits**: View and manage rate limit configurations\n",
    "- **Provider Management**: Enable/disable providers, set priorities\n",
    "- **Model Management**: Browse and search available models\n",
    "- **Monitoring**: Real-time monitoring and alerting\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "1. Installed dependencies: `poetry install`\n",
    "2. Configured API keys in `.env`\n",
    "3. Initialized database: `alembic upgrade head`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920dbc5f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following cell sets up the environment to run CLI commands from the project root directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0a257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Working directory: /home/goddess/dev/projects/anna's-gift\n",
      "✅ Project root: /home/goddess/dev/projects/anna's-gift\n",
      "✅ Python path includes project root: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root directory (where this notebook is located)\n",
    "project_root = Path().resolve()\n",
    "if 'docs' in str(project_root):\n",
    "    project_root = project_root.parent\n",
    "\n",
    "# Change to project root directory\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"✅ Working directory: {os.getcwd()}\")\n",
    "print(f\"✅ Project root: {project_root}\")\n",
    "print(f\"✅ Python path includes project root: {str(project_root) in sys.path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0440d01d",
   "metadata": {},
   "source": [
    "## 1. Usage Monitoring\n",
    "\n",
    "Track API usage, costs, and statistics across all providers and models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e85081",
   "metadata": {},
   "source": [
    "### 1.1 Overall Usage Statistics\n",
    "\n",
    "View overall usage across all providers for the last 24 hours:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369ba9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for the specified time window\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage show --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da6573",
   "metadata": {},
   "source": [
    "### 1.2 Provider-Specific Usage\n",
    "\n",
    "View usage for a specific provider (e.g., Groq):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a11f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for groq\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage provider groq --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1c5ce",
   "metadata": {},
   "source": [
    "### 1.3 Model-Specific Usage\n",
    "\n",
    "View usage for a specific model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c334dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for groq/llama-\u001b[0m\u001b[1;33m3.1\u001b[0m\u001b[33m-8b-instant\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage model groq llama-3.1-8b-instant --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c65e1",
   "metadata": {},
   "source": [
    "### 1.4 Cost Breakdown\n",
    "\n",
    "View cost breakdown across all providers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d8e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for cost calculation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage cost --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab1893",
   "metadata": {},
   "source": [
    "## 2. Rate Limit Management\n",
    "\n",
    "View and understand rate limit configurations for all providers and models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40840ee6",
   "metadata": {},
   "source": [
    "### 2.1 List All Rate Limits\n",
    "\n",
    "View all rate limit configurations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6976761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                           Rate Limit Configurations                            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTPM  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mNotes        \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ github-copil… │ default        │ 60.00    │ 5.00K    │ N/A   │ Pro account   │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│               │                │          │          │       │ Actual limits │\n",
      "│               │                │          │          │       │ may vary by   │\n",
      "│               │                │          │          │       │ account tier. │\n",
      "│ groq          │ default        │ 30.00    │ 1.00K    │ N/A   │ Free tier     │\n",
      "│               │                │          │          │       │ limits. Paid  │\n",
      "│               │                │          │          │       │ tiers have    │\n",
      "│               │                │          │          │       │ higher        │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ groq          │ llama-3.1-8b-… │ 30.00    │ 1.00K    │ N/A   │ Fast model,   │\n",
      "│               │                │          │          │       │ higher        │\n",
      "│               │                │          │          │       │ throughput    │\n",
      "│               │                │          │          │       │ possible.     │\n",
      "│ groq          │ llama-3.1-405… │ 10.00    │ 500.00   │ N/A   │ Large model,  │\n",
      "│               │                │          │          │       │ lower rate    │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ deepseek      │ default        │ 1000.00K │ 1000.00K │ N/A   │ No official   │\n",
      "│               │                │          │          │       │ rate limits.  │\n",
      "│               │                │          │          │       │ May           │\n",
      "│               │                │          │          │       │ experience    │\n",
      "│               │                │          │          │       │ throttling    │\n",
      "│               │                │          │          │       │ during high   │\n",
      "│               │                │          │          │       │ traffic.      │\n",
      "│ openrouter    │ default        │ 100.00   │ 5.00K    │ N/A   │ Limits vary   │\n",
      "│               │                │          │          │       │ by account    │\n",
      "│               │                │          │          │       │ tier and      │\n",
      "│               │                │          │          │       │ underlying    │\n",
      "│               │                │          │          │       │ model         │\n",
      "│               │                │          │          │       │ provider.     │\n",
      "│ gemini        │ gemini-2.0-fl… │ 2.00K    │ 1000.00K │ 4.00M │ Tier 1 pro    │\n",
      "│               │                │          │          │       │ account       │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ gemini        │ gemini-2.0-fl… │ 4.00K    │ 1000.00K │ 4.00M │ Tier 1 pro    │\n",
      "│               │                │          │          │       │ account       │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ gemini        │ gemini-1.5-fl… │ 2.00K    │ 1000.00K │ 4.00M │ Tier 1 pro    │\n",
      "│               │                │          │          │       │ account       │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ gemini        │ gemini-1.5-pro │ 1.00K    │ 1000.00K │ 4.00M │ Tier 1 pro    │\n",
      "│               │                │          │          │       │ account       │\n",
      "│               │                │          │          │       │ limits.       │\n",
      "│ mistral       │ default        │ 50.00    │ 2.00K    │ N/A   │ Limits vary   │\n",
      "│               │                │          │          │       │ by account    │\n",
      "│               │                │          │          │       │ tier.         │\n",
      "│ mistral       │ mistral-tiny   │ 100.00   │ 5.00K    │ N/A   │               │\n",
      "│ mistral       │ mistral-large… │ 20.00    │ 1.00K    │ N/A   │               │\n",
      "│ codestral     │ default        │ 50.00    │ 2.00K    │ N/A   │ Same rate     │\n",
      "│               │                │          │          │       │ limit         │\n",
      "│               │                │          │          │       │ structure as  │\n",
      "│               │                │          │          │       │ Mistral AI.   │\n",
      "└───────────────┴────────────────┴──────────┴──────────┴───────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main rates list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd37dc7",
   "metadata": {},
   "source": [
    "### 2.2 Provider Rate Limits\n",
    "\n",
    "View rate limits for a specific provider:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5256359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                              Rate Limits for groq                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTPM\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mNotes                     \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ default                  │ 30.00 │ 1.00K  │ N/A │ Free tier limits. Paid     │\n",
      "│                          │       │        │     │ tiers have higher limits.  │\n",
      "│ llama-3.1-8b-instant     │ 30.00 │ 1.00K  │ N/A │ Fast model, higher         │\n",
      "│                          │       │        │     │ throughput possible.       │\n",
      "│ llama-3.1-405b-reasoning │ 10.00 │ 500.00 │ N/A │ Large model, lower rate    │\n",
      "│                          │       │        │     │ limits.                    │\n",
      "└──────────────────────────┴───────┴────────┴─────┴────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main rates provider groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ff1c8",
   "metadata": {},
   "source": [
    "### 2.3 Model Rate Limits\n",
    "\n",
    "View rate limits for a specific model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca08df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m            Rate Limits for groq/llama-3.1-8b-instant            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mSetting            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mValue                                  \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ Requests Per Minute │ 30.00                                   │\n",
      "│ Requests Per Day    │ 1.00K                                   │\n",
      "│ Notes               │ Fast model, higher throughput possible. │\n",
      "└─────────────────────┴─────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main rates model groq llama-3.1-8b-instant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fb39b",
   "metadata": {},
   "source": [
    "### 2.4 Remaining Rate Limits\n",
    "\n",
    "View remaining rate limits based on current usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ae06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                        Remaining Rate Limits (Last 1h)                         \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
      "┃\u001b[1;35m         \u001b[0m┃\u001b[1;35m         \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD   \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvid…\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mLimit  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mUsed   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRemain…\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mLimit  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mUsed   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRemai…\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
      "│ codest… │ default │ 50.00   │ 0.00    │ \u001b[32m50\u001b[0m      │ 2.00K   │ 0.00    │ 2000   │\n",
      "│ deepse… │ default │ 1000.0… │ 0.00    │ \u001b[32m999999\u001b[0m  │ 1000.0… │ 0.00    │ 999999 │\n",
      "│ github… │ default │ 60.00   │ 0.00    │ \u001b[32m60\u001b[0m      │ 5.00K   │ 0.00    │ 5000   │\n",
      "│ groq    │ default │ 30.00   │ 0.00    │ \u001b[32m30\u001b[0m      │ 1.00K   │ 0.00    │ 1000   │\n",
      "│ mistral │ default │ 50.00   │ 0.00    │ \u001b[32m50\u001b[0m      │ 2.00K   │ 0.00    │ 2000   │\n",
      "│ openro… │ default │ 100.00  │ 0.00    │ \u001b[32m100\u001b[0m     │ 5.00K   │ 0.00    │ 5000   │\n",
      "└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main rates remaining --hours 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29b000",
   "metadata": {},
   "source": [
    "## 3. Provider Management\n",
    "\n",
    "Manage provider configurations, enable/disable providers, and set priorities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13dbef",
   "metadata": {},
   "source": [
    "### 3.1 List All Providers\n",
    "\n",
    "View all providers with their status:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9e711a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                   Providers                                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mEnabled\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPriority\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBase URL                              \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ github-copilot │ \u001b[32m✓\u001b[0m       │ 1        │ https://models.github.ai               │\n",
      "│ deepseek       │ \u001b[32m✓\u001b[0m       │ 2        │ https://api.deepseek.com               │\n",
      "│ groq           │ \u001b[32m✓\u001b[0m       │ 3        │ https://api.groq.com/openai/v1         │\n",
      "│ mistral        │ \u001b[32m✓\u001b[0m       │ 4        │ https://api.mistral.ai/v1              │\n",
      "│ codestral      │ \u001b[32m✓\u001b[0m       │ 5        │ https://api.mistral.ai/v1              │\n",
      "│ openrouter     │ \u001b[32m✓\u001b[0m       │ 6        │ https://openrouter.ai/api/v1           │\n",
      "│ gemini         │ \u001b[32m✓\u001b[0m       │ 7        │ https://generativelanguage.googleapis… │\n",
      "└────────────────┴─────────┴──────────┴────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main providers list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261b609",
   "metadata": {},
   "source": [
    "### 3.2 Provider Status\n",
    "\n",
    "View detailed status for a specific provider:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe78e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m               Status for groq                \u001b[0m\n",
      "┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mSetting  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mValue                         \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ Enabled   │ Yes                            │\n",
      "│ Priority  │ 3                              │\n",
      "│ Base URL  │ https://api.groq.com/openai/v1 │\n",
      "│ RPM Limit │ 600                            │\n",
      "│ RPD Limit │ 10000                          │\n",
      "└───────────┴────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main providers status groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727f5a4",
   "metadata": {},
   "source": [
    "### 3.3 Enable/Disable Providers\n",
    "\n",
    "Enable a provider:\n",
    "```bash\n",
    "poetry run python -m app.cli.main providers enable groq\n",
    "```\n",
    "\n",
    "Disable a provider:\n",
    "```bash\n",
    "poetry run python -m app.cli.main providers disable mistral\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2b3f8",
   "metadata": {},
   "source": [
    "### 3.4 Set Provider Priority\n",
    "\n",
    "Set provider priority (lower number = higher priority):\n",
    "```bash\n",
    "poetry run python -m app.cli.main providers priority groq 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e811c9",
   "metadata": {},
   "source": [
    "### 3.5 Health Checks\n",
    "\n",
    "Run health checks on all providers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe452ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m           Provider Health            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mStatus \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mEnabled\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ github-copilot │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ deepseek       │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ groq           │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ mistral        │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ codestral      │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ openrouter     │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "│ gemini         │ \u001b[32mhealthy\u001b[0m │ ✓       │\n",
      "└────────────────┴─────────┴─────────┘\n",
      "\u001b[33m⚠\u001b[0m Full health checks require running server. Use API endpoint for detailed \n",
      "health status.\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main providers health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efc7bc",
   "metadata": {},
   "source": [
    "## 4. Model Management\n",
    "\n",
    "Browse, search, and explore available models across all providers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d74d3c",
   "metadata": {},
   "source": [
    "### 4.1 List All Models\n",
    "\n",
    "View all available models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddec3f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                Available Models                                \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ codestral      │ codestral-latest               │ fast     │ N/A             │\n",
      "│ codestral      │ codestral-mamba-latest         │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-chat                  │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-coder                 │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-flash               │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro                 │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro-latest          │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-2.0-flash-exp           │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-haiku       │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-opus        │ powerful │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet      │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-3.5-turbo           │ fast     │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4-turbo             │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4o                  │ powerful │ N/A             │\n",
      "│ groq           │ gemma-7b-it                    │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.1-405b-reasoning       │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-70b-versatile        │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-8b-instant           │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.3-70b-versatile        │ powerful │ N/A             │\n",
      "│ groq           │ mixtral-8x7b-32768             │ fast     │ N/A             │\n",
      "│ mistral        │ mistral-7b-instruct            │ fast     │ N/A             │\n",
      "│ mistral        │ mistral-large-latest           │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-medium                 │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-small                  │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-tiny                   │ fast     │ N/A             │\n",
      "│ openrouter     │ meta-llama/llama-3.1-8b-instr… │ fast     │ N/A             │\n",
      "│ openrouter     │ microsoft/phi-3-mini-4k-instr… │ fast     │ N/A             │\n",
      "└────────────────┴────────────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m27\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513cc43",
   "metadata": {},
   "source": [
    "### 4.2 List Free Models Only\n",
    "\n",
    "View only free models (no credits required):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34705fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                             Available Models                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ deepseek       │ deepseek-chat             │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-coder            │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-flash          │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro            │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro-latest     │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-2.0-flash-exp      │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-haiku  │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-opus   │ powerful │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-3.5-turbo      │ fast     │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4-turbo        │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4o             │ powerful │ N/A             │\n",
      "│ groq           │ gemma-7b-it               │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.1-405b-reasoning  │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-70b-versatile   │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-8b-instant      │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.3-70b-versatile   │ powerful │ N/A             │\n",
      "│ groq           │ mixtral-8x7b-32768        │ fast     │ N/A             │\n",
      "└────────────────┴───────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list --free-only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659a5e5",
   "metadata": {},
   "source": [
    "### 4.3 Filter by Provider\n",
    "\n",
    "List models for a specific provider:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2075ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                     Models for groq                     \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ gemma-7b-it              │ fast     │ N/A             │\n",
      "│ llama-3.1-405b-reasoning │ powerful │ N/A             │\n",
      "│ llama-3.1-70b-versatile  │ powerful │ N/A             │\n",
      "│ llama-3.1-8b-instant     │ fast     │ N/A             │\n",
      "│ llama-3.3-70b-versatile  │ powerful │ N/A             │\n",
      "│ mixtral-8x7b-32768       │ fast     │ N/A             │\n",
      "└──────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m6\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models provider groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e127f7",
   "metadata": {},
   "source": [
    "### 4.4 Filter by Category\n",
    "\n",
    "List models by category (fast or powerful):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd71636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                Available Models                                \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ codestral      │ codestral-latest               │ fast     │ N/A             │\n",
      "│ codestral      │ codestral-mamba-latest         │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-chat                  │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-coder                 │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-flash               │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-2.0-flash-exp           │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-haiku       │ fast     │ N/A             │\n",
      "│ github-copilot │ openai/gpt-3.5-turbo           │ fast     │ N/A             │\n",
      "│ groq           │ gemma-7b-it                    │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.1-8b-instant           │ fast     │ N/A             │\n",
      "│ groq           │ mixtral-8x7b-32768             │ fast     │ N/A             │\n",
      "│ mistral        │ mistral-7b-instruct            │ fast     │ N/A             │\n",
      "│ mistral        │ mistral-tiny                   │ fast     │ N/A             │\n",
      "│ openrouter     │ meta-llama/llama-3.1-8b-instr… │ fast     │ N/A             │\n",
      "│ openrouter     │ microsoft/phi-3-mini-4k-instr… │ fast     │ N/A             │\n",
      "└────────────────┴────────────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list --category fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18abf154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                             Available Models                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ gemini         │ gemini-1.5-pro            │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro-latest     │ powerful │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-opus   │ powerful │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4-turbo        │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4o             │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-405b-reasoning  │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-70b-versatile   │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.3-70b-versatile   │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-large-latest      │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-medium            │ powerful │ N/A             │\n",
      "│ mistral        │ mistral-small             │ powerful │ N/A             │\n",
      "└────────────────┴───────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list --category powerful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60385713",
   "metadata": {},
   "source": [
    "### 4.5 Model Details\n",
    "\n",
    "View detailed information for a specific model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a8b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m          Model Details:           \u001b[0m\n",
      "\u001b[3m     groq/llama-3.1-8b-instant     \u001b[0m\n",
      "┏━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProperty\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mValue               \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ Provider │ groq                 │\n",
      "│ Model    │ llama-3.1-8b-instant │\n",
      "│ Category │ fast                 │\n",
      "└──────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models show groq llama-3.1-8b-instant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f85e8",
   "metadata": {},
   "source": [
    "### 4.6 Search Models\n",
    "\n",
    "Search for models by name:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d75bbc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                 Search Results for 'llama'                 \u001b[0m\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
      "│ groq       │ llama-3.1-405b-reasoning         │ powerful │\n",
      "│ groq       │ llama-3.1-70b-versatile          │ powerful │\n",
      "│ groq       │ llama-3.1-8b-instant             │ fast     │\n",
      "│ groq       │ llama-3.3-70b-versatile          │ powerful │\n",
      "│ openrouter │ meta-llama/llama-3.1-8b-instruct │ fast     │\n",
      "└────────────┴──────────────────────────────────┴──────────┘\n",
      "\n",
      "\u001b[2mFound: \u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models search llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8857fa",
   "metadata": {},
   "source": [
    "### 4.7 Models by Category\n",
    "\n",
    "View models organized by category (fast vs powerful):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c3f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                              Fast Models                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ codestral      │ codestral-latest                 │ 70.00           │\n",
      "│ codestral      │ codestral-mamba-latest           │ N/A             │\n",
      "│ deepseek       │ deepseek-chat                    │ 73.00           │\n",
      "│ deepseek       │ deepseek-coder                   │ N/A             │\n",
      "│ gemini         │ gemini-1.5-flash                 │ 74.00           │\n",
      "│ gemini         │ gemini-2.0-flash-exp             │ 72.00           │\n",
      "│ github-copilot │ anthropic/claude-3-haiku         │ 75.00           │\n",
      "│ github-copilot │ openai/gpt-3.5-turbo             │ 70.00           │\n",
      "│ groq           │ gemma-7b-it                      │ N/A             │\n",
      "│ groq           │ llama-3.1-8b-instant             │ 68.00           │\n",
      "│ groq           │ mixtral-8x7b-32768               │ 70.00           │\n",
      "│ mistral        │ mistral-7b-instruct              │ 68.00           │\n",
      "│ mistral        │ mistral-tiny                     │ 65.00           │\n",
      "│ openrouter     │ meta-llama/llama-3.1-8b-instruct │ N/A             │\n",
      "│ openrouter     │ microsoft/phi-3-mini-4k-instruct │ N/A             │\n",
      "└────────────────┴──────────────────────────────────┴─────────────────┘\n",
      "\n",
      "\u001b[3m                        Powerful Models                         \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ gemini         │ gemini-1.5-pro            │ 84.00           │\n",
      "│ gemini         │ gemini-1.5-pro-latest     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-opus   │ 87.00           │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet │ 82.00           │\n",
      "│ github-copilot │ openai/gpt-4-turbo        │ 87.00           │\n",
      "│ github-copilot │ openai/gpt-4o             │ 88.00           │\n",
      "│ groq           │ llama-3.1-405b-reasoning  │ 85.00           │\n",
      "│ groq           │ llama-3.1-70b-versatile   │ 80.00           │\n",
      "│ groq           │ llama-3.3-70b-versatile   │ 82.00           │\n",
      "│ mistral        │ mistral-large-latest      │ 83.00           │\n",
      "│ mistral        │ mistral-medium            │ N/A             │\n",
      "│ mistral        │ mistral-small             │ N/A             │\n",
      "└────────────────┴───────────────────────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mFast: \u001b[0m\u001b[1;2;36m15\u001b[0m\u001b[2m models, Powerful: \u001b[0m\u001b[1;2;36m12\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models categorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37c644",
   "metadata": {},
   "source": [
    "## 5. Monitoring\n",
    "\n",
    "Real-time monitoring, error tracking, and performance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f3455",
   "metadata": {},
   "source": [
    "### 5.1 Recent Errors\n",
    "\n",
    "View recent errors across all providers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cd49dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mNo errors found in the last \u001b[0m\u001b[1;32m24\u001b[0m\u001b[32m hours\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main monitor errors --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7b2ba",
   "metadata": {},
   "source": [
    "### 5.2 Performance Metrics\n",
    "\n",
    "View performance metrics for all providers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e947b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Performance Metrics (Last 24h)                     \u001b[0m\n",
      "┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRequests\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mAvg Tokens/Req\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mError Rate\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRate Limit Hits\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "└──────────┴──────────┴────────────────┴────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main monitor performance --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8db1c",
   "metadata": {},
   "source": [
    "### 5.3 Active Alerts\n",
    "\n",
    "View active alerts and warnings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8e898d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mNo active alerts\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main monitor alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63879aec",
   "metadata": {},
   "source": [
    "### 5.4 Live Monitoring\n",
    "\n",
    "Start live monitoring dashboard (runs continuously):\n",
    "```bash\n",
    "poetry run python -m app.cli.main monitor live --interval 5\n",
    "```\n",
    "\n",
    "Note: This command runs continuously and updates every 5 seconds. Press Ctrl+C to stop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c00708",
   "metadata": {},
   "source": [
    "### 5.5 Watch Mode\n",
    "\n",
    "Watch mode with auto-refresh:\n",
    "```bash\n",
    "poetry run python -m app.cli.main monitor watch --interval 5\n",
    "```\n",
    "\n",
    "Note: This command runs continuously and refreshes every 5 seconds. Press Ctrl+C to stop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95064708",
   "metadata": {},
   "source": [
    "## 6. Common Use Cases\n",
    "\n",
    "Practical workflows and examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f49803",
   "metadata": {},
   "source": [
    "### 6.1 Quick Health Check\n",
    "\n",
    "Check the status of all providers and view recent usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72995e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                                   Providers                                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mEnabled\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mPriority\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBase URL                              \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ github-copilot │ \u001b[32m✓\u001b[0m       │ 1        │ https://models.github.ai               │\n",
      "│ deepseek       │ \u001b[32m✓\u001b[0m       │ 2        │ https://api.deepseek.com               │\n",
      "│ groq           │ \u001b[32m✓\u001b[0m       │ 3        │ https://api.groq.com/openai/v1         │\n",
      "│ mistral        │ \u001b[32m✓\u001b[0m       │ 4        │ https://api.mistral.ai/v1              │\n",
      "│ codestral      │ \u001b[32m✓\u001b[0m       │ 5        │ https://api.mistral.ai/v1              │\n",
      "│ openrouter     │ \u001b[32m✓\u001b[0m       │ 6        │ https://openrouter.ai/api/v1           │\n",
      "│ gemini         │ \u001b[32m✓\u001b[0m       │ 7        │ https://generativelanguage.googleapis… │\n",
      "└────────────────┴─────────┴──────────┴────────────────────────────────────────┘\n",
      "---\n",
      "\u001b[33mNo usage data found for the specified time window\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main providers list && echo \"---\" && poetry run python -m app.cli.main usage show --hours 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b29a1",
   "metadata": {},
   "source": [
    "### 6.2 Find Free Models\n",
    "\n",
    "Find all free models available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91cc4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                             Available Models                              \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ deepseek       │ deepseek-chat             │ fast     │ N/A             │\n",
      "│ deepseek       │ deepseek-coder            │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-flash          │ fast     │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro            │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-1.5-pro-latest     │ powerful │ N/A             │\n",
      "│ gemini         │ gemini-2.0-flash-exp      │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-haiku  │ fast     │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-opus   │ powerful │ N/A             │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-3.5-turbo      │ fast     │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4-turbo        │ powerful │ N/A             │\n",
      "│ github-copilot │ openai/gpt-4o             │ powerful │ N/A             │\n",
      "│ groq           │ gemma-7b-it               │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.1-405b-reasoning  │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-70b-versatile   │ powerful │ N/A             │\n",
      "│ groq           │ llama-3.1-8b-instant      │ fast     │ N/A             │\n",
      "│ groq           │ llama-3.3-70b-versatile   │ powerful │ N/A             │\n",
      "│ groq           │ mixtral-8x7b-32768        │ fast     │ N/A             │\n",
      "└────────────────┴───────────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m18\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list --free-only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a884eb0d",
   "metadata": {},
   "source": [
    "### 6.3 Check Rate Limits\n",
    "\n",
    "Check current rate limits and remaining capacity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14aef6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                        Remaining Rate Limits (Last 1h)                         \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
      "┃\u001b[1;35m         \u001b[0m┃\u001b[1;35m         \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPM    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRPD   \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvid…\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mLimit  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mUsed   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRemain…\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mLimit  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mUsed   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mRemai…\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
      "│ codest… │ default │ 50.00   │ 0.00    │ \u001b[32m50\u001b[0m      │ 2.00K   │ 0.00    │ 2000   │\n",
      "│ deepse… │ default │ 1000.0… │ 0.00    │ \u001b[32m999999\u001b[0m  │ 1000.0… │ 0.00    │ 999999 │\n",
      "│ github… │ default │ 60.00   │ 0.00    │ \u001b[32m60\u001b[0m      │ 5.00K   │ 0.00    │ 5000   │\n",
      "│ groq    │ default │ 30.00   │ 0.00    │ \u001b[32m30\u001b[0m      │ 1.00K   │ 0.00    │ 1000   │\n",
      "│ mistral │ default │ 50.00   │ 0.00    │ \u001b[32m50\u001b[0m      │ 2.00K   │ 0.00    │ 2000   │\n",
      "│ openro… │ default │ 100.00  │ 0.00    │ \u001b[32m100\u001b[0m     │ 5.00K   │ 0.00    │ 5000   │\n",
      "└─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main rates remaining --hours 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f11d9",
   "metadata": {},
   "source": [
    "### 6.4 Cost Analysis\n",
    "\n",
    "Analyze costs for the last 24 hours:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3355299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for cost calculation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage cost --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc569245",
   "metadata": {},
   "source": [
    "### 6.5 Provider Comparison\n",
    "\n",
    "Compare usage across multiple providers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b83c52ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for groq\u001b[0m\n",
      "---\n",
      "\u001b[33mNo usage data found for deepseek\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage provider groq --hours 24 && echo \"---\" && poetry run python -m app.cli.main usage provider deepseek --hours 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4cd01",
   "metadata": {},
   "source": [
    "## 7. Advanced Usage\n",
    "\n",
    "Advanced workflows and tips.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d004345",
   "metadata": {},
   "source": [
    "### 7.1 Combining Filters\n",
    "\n",
    "Combine multiple filters to find specific models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f70365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                        Available Models                        \u001b[0m\n",
      "┏━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mBenchmark Score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ groq     │ gemma-7b-it          │ fast     │ N/A             │\n",
      "│ groq     │ llama-3.1-8b-instant │ fast     │ N/A             │\n",
      "│ groq     │ mixtral-8x7b-32768   │ fast     │ N/A             │\n",
      "└──────────┴──────────────────────┴──────────┴─────────────────┘\n",
      "\n",
      "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models list --provider groq --category fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eb540",
   "metadata": {},
   "source": [
    "### 7.2 Time Window Analysis\n",
    "\n",
    "Analyze usage over different time windows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2950b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNo usage data found for the specified time window\u001b[0m\n",
      "---Last Hour---\n",
      "\u001b[33mNo usage data found for the specified time window\u001b[0m\n",
      "---Last 24 Hours---\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main usage show --hours 1 && echo \"---Last Hour---\" && poetry run python -m app.cli.main usage show --hours 24 && echo \"---Last 24 Hours---\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc66133",
   "metadata": {},
   "source": [
    "### 7.3 Model Discovery\n",
    "\n",
    "Discover models by searching for capabilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd507ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m          Search Results for 'gemini'          \u001b[0m\n",
      "┏━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
      "│ gemini   │ gemini-1.5-flash      │ fast     │\n",
      "│ gemini   │ gemini-1.5-pro        │ powerful │\n",
      "│ gemini   │ gemini-1.5-pro-latest │ powerful │\n",
      "│ gemini   │ gemini-2.0-flash-exp  │ fast     │\n",
      "└──────────┴───────────────────────┴──────────┘\n",
      "\n",
      "\u001b[2mFound: \u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[2m models\u001b[0m\n",
      "---\n",
      "\u001b[3m               Search Results for 'claude'               \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35mProvider      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mCategory\u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
      "│ github-copilot │ anthropic/claude-3-haiku  │ fast     │\n",
      "│ github-copilot │ anthropic/claude-3-opus   │ powerful │\n",
      "│ github-copilot │ anthropic/claude-3-sonnet │ powerful │\n",
      "└────────────────┴───────────────────────────┴──────────┘\n",
      "\n",
      "\u001b[2mFound: \u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[2m models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"/home/goddess/dev/projects/anna's-gift\" && poetry run python -m app.cli.main models search gemini && echo \"---\" && poetry run python -m app.cli.main models search claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31687b94",
   "metadata": {},
   "source": [
    "## 8. Tips and Best Practices\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "All commands support `--help` flag:\n",
    "```bash\n",
    "poetry run python -m app.cli.main --help\n",
    "poetry run python -m app.cli.main usage --help\n",
    "poetry run python -m app.cli.main models --help\n",
    "```\n",
    "\n",
    "### Command Shortcuts\n",
    "\n",
    "Many commands support short flags:\n",
    "- `-h` for `--hours`\n",
    "- `-p` for `--provider`\n",
    "- `-c` for `--category`\n",
    "- `-i` for `--interval`\n",
    "- `-l` for `--limit`\n",
    "\n",
    "### Output Formatting\n",
    "\n",
    "The CLI uses Rich library for beautiful terminal output:\n",
    "- Color-coded status indicators\n",
    "- Formatted tables\n",
    "- Progress indicators\n",
    "- Markdown-style formatting\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Use time windows wisely**: Smaller time windows (1-6 hours) are faster\n",
    "2. **Filter early**: Use provider/model filters to reduce data\n",
    "3. **Monitor in background**: Use `monitor live` for continuous monitoring\n",
    "4. **Cache results**: Some commands cache results for faster subsequent runs\n",
    "\n",
    "### Integration with Scripts\n",
    "\n",
    "You can use the CLI in shell scripts:\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# Check if any providers are disabled\n",
    "DISABLED=$(poetry run python -m app.cli.main providers list | grep \"✗\" | wc -l)\n",
    "if [ $DISABLED -gt 0 ]; then\n",
    "    echo \"Warning: $DISABLED providers are disabled\"\n",
    "fi\n",
    "```\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "The CLI provides clear error messages:\n",
    "- Missing configuration files\n",
    "- Invalid provider/model names\n",
    "- Database connection issues\n",
    "- API key problems\n",
    "\n",
    "All errors include suggestions for resolution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anna's Gift)",
   "language": "python",
   "name": "annas-gift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
